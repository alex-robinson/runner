# runner

Sample parameters, run model ensemble, submit to high-performance cluster queues

Install
=======
    python setup.py install

Usage
=====
Use command-line help:

    job --help

And for each sub-command:

    job product --help
    job sample --help
    job resample --help
    job run --help


Examples
========

Parameter sampling
------------------

Factorial combination of parameters:

    job product a=2,3,4 b=0,1
    
     a      b
     2      0
     2      1
     3      0
     3      1
     4      0
     4      1

Monte-carlo sampling:

    job sample a=U?0,1 b=N?0,1 --size 10 --seed 4

         a      b
    0.425298236238 0.988953805595
    0.904416005793 2.62482283016
    0.68629932356 0.705445219934
    0.397627445478 -0.766770633921
    0.577938292179 -0.522609467132
    0.0967029839014 -0.14215407458
    0.71638422414 0.0495725958965
    0.26977288246 0.519632323554
    0.197268435996 -1.60068615198
    0.800898609767 -0.948326628599

The above command draws 10 samples from "a" as uniform distribution between 0 
and 1 and "b" as normal distribution of mean 0 and standard deviation 1. 
The seed parameter sets the random state, to make the sampling reproducible.
Sampling method defaults to Latin Hypercube Sampling, built on the pyDOE 
package (copied in runner to reduce external dependencies).


Run model ensemble
------------------

The canonical form of `job run` is:

    job run [OPTIONS] -- EXECUTABLE [OPTIONS]

where `EXECUTABLE` is your model executable or a command, followed by its
arguments. Note the `--` that separates `job run` arguments `OPTIONS` from the
executable.  When there is no ambiguity in the command-line arguments (as seen
by python's argparse) it may be dropped. `job run` options determine in which
manner to run the model, which parameter values to vary (the ensemble), and how
to communicate these parameter values to the model.  The most straightforward
way it to use formattable command-line argument. For instance using canonical
UNIX command `echo` as executable:

    job run -p a=2,3,4 b=0,1 -o out --shell -- echo --a {a} --b {b} --out {}

    --a 2 --b 0 --out out/0
    --a 2 --b 1 --out out/1
    --a 3 --b 0 --out out/2
    --a 3 --b 1 --out out/3
    --a 4 --b 0 --out out/4
    --a 4 --b 1 --out out/5

The command above runs an ensemble of 6 model versions, by calling 
`echo --a {a} --b {b} --out {}`  where `{a}`, `{b}` and `{}` 
are formatted using runtime with
parameter and run directory values, as displayed in the output above.
Parameter ensembles generated by `job sample` can also be provided as input via
`-i/--params-file` option instead of `-p/--params`. 
The `job run` parameter `-o/--out-dir` indicates experiment directory, under
which individual ensemble member run directories `{}` will be created. There
are a number of options to determine how this should be done (e.g.
`-a/--auto-dir` to create sub-directory based on parameter names and values).
Without `--shell`, the command would be run in the background, in parallel
subprocesses. Alternatively, `--submit` would submit the job via `SLURM`. 

There are a number of other ways to communicate parameter values to your model
(see also `--arg-prefix` parameter, e.g. with `--arg-prefix "--{} "` to achieve
the same result with less redundancy, when parameter names match). Parameters
can also be passed via a file:

    job run -p a=2,3,4 b=0,1 -o out --file-name "params.txt" --file-type "linesep" --line-sep " " --shell cat {}/params.txt

    a 2
    b 0
    a 2
    b 1
    a 3
    b 0
    a 3
    b 1
    a 4
    b 0
    a 4
    b 1

with a number of other file types. File types that involve grouping, such as
namelist, require a group prefix with a `.` separator in the parameter name:

    job run -p g1.a=0,1 g2.b=2. -o out --file-name "params.txt" --file-type "namelist" --shell  cat {}/params.txt

    &g1
     a               = 0          
    /
    &g2
     b               = 2.0        
    /
    &g1
     a               = 1          
    /
    &g2
     b               = 2.0        
    /

Additionally, parameters can be set as environment variables via `--env-prefix`
argument (e.g. `--env-prefix ""` for direct access via `$NAME` within the
script).


Resample an existing parameter set
==================================

    job resample --help


Summary
-------
Resample an existing ensemble, based on an array of weights.
Optionally, a scaled version of the weights may be used, with 
addition of noise, according to Annan and Hargreave's Iterative Importance Sampling.

Background
----------
Typically, weights can be derived from a Bayesian analysis, where each
realization is compared with observations and assigned a likelihood.  An array
of resampling indices can be derived from the weights, where realizations with
large weights are resampled several times, while realization with small weights
are not resampled.  To avoid the exact same parameter set to appear duplicated
in the resampled ensemble, introduction of noise (jitter) is necessary, which
conserves statistical properties of the resampled ensemble (covariance).

The problem is not trivial and several approaches exist for both the sampling
of indices and the addition of noise. Basically, differences in resampling
methods (before application of jitter) mainly affect how the tail - low-weights
realizations - are dealt with, which influences the results for "small"
ensemble size:

- multinomial : random sampling based on empirical distribution function.
    Simple but poor performance.
- residual : some of the resampling indices can be determined deterministically 
    when weights are large enough, i.e. `w_i * N > 1` where `w_i` represents 
    a normalized weight (sum of all weights equals 1), and N is the ensemble size.
    The array of weight residuals (`w_i * N - int(w_i * N)`) is then resampled
    using a basic multinomial approach.

More advanced methods are typically similar to `residual`, but the array of
residual weights is resampled taking into account the uniformity of samples in
the parameter or state space (and therefore requires additional information).
One of these methods, coined `deterministic` (re)sampling, is planned to be
implemented, in addition to the two mentioned above.

The jittering step is tricky because the noise is unlikely to have a pure
(multivariate) normal distribution (especially when the model is strongly non
linear).  An approach proposed by Annan and Heargraves, "iterative importance
sampling" (`iis`), is to sample jitter with zero mean and covariance computed from the
original (resampled) ensemble but scaled so that its variance is only a small
fraction `epsilon` of the original ensemble. Addition of noise increases
overall covariance by `1 + epsilon`, but they show that this can balance out if
the weights used for resampling are "flattened" with the same `epsilon` as an
exponent (`shrinking`).  This procedure leaves the posterior distribution
invariant, so that it can be applied iteratively when starting from a prior
which is far from the posterior. 

One step of this resampling procedure can be activated with the `--iis` flag.
By default the epsilon factor is computed automatically to keep an "effective
ensemble size" in a reasonable proportion (50% to 90%) to the actual ensemble
size (see `--neff-bounds` parameter). No other jittering method is proposed.

References
----------
Annan, J. D., & Hargreaves, J. C. (2010). Efficient identification of 
ocean thermodynamics in a physical/biogeochemical ocean model with an iterative 
Importance Sampling method. Ocean Modelling, 32(3-4), 205-215. 
doi:10.1016/j.ocemod.2010.02.003

Douc and Cappe. 2005. Comparison of resampling schemes for particle filtering.
ISPA2005, Proceedings of the 4th Symposium on Image and Signal Processing.

Hol, Jeroen D., Thomas B. Sch√∂n, and Fredrik Gustafsson, 
"On Resampling Algorithms for Particle Filters", 
in NSSPW - Nonlinear Statistical Signal Processing Workshop 2006, 
2006 <http://dx.doi.org/10.1109/NSSPW.2006.4378824>
